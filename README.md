# CSU_AISafetySecurity

AI presents opportunities to greatly improve medicine, product development, and even teaching itself, yet there are also conncerns that it may be misused or deployed in unsafe ways. Given the challenges of testing and releasing safe AI, ensuring that AI deployment follows state-of-the-art security procedures is critical. At the same time, AI itself could be used to find and exploit security vulnerabilities in code or generate phishing attacks. We need both AI in security and security in AI. Given recent AI technical advances and recent regulatory discussions, now is the time for the CSU community to find a forum where these issues can be discussed and on occasion speak as a community about these issues.

# Key technology milestones
  * Table 1 of the [GPT-4 technical report](https://arxiv.org/pdf/2303.08774.pdf) discusses its ability to perform well on a variety of AP, GRE, and SAT tests.
  * Text to video advances like [Sora](https://openai.com/sora) allow expressive ideas to be generated easly but also increase risks of deepfakes.

# Key policy milestones
  * In February 2019, the Executive Office of the president issued an executive order on [Maintaining American Leadership in AI](https://www.federalregister.gov/documents/2019/02/14/2019-02544/maintaining-american-leadership-in-artificial-intelligence)
  * In January 2023, NIST (US National Institute of Standards) release the [AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework) to better manage risks to individual, organizations and society associated with AI.
  * In October 2023, the Executive Office of the president of the US issued an [Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/) to help govern the use of AI safely and responsibly.
  * In November 2023, the [Bletchley declaration](https://www.theguardian.com/technology/2023/nov/01/uk-us-eu-and-china-sign-declaration-of-ais-catastrophic-danger) was signed by countries attending the AI Safety Summit declared that AI poses a potentially catastrophic risk to humanity and the countries pledged together to reduce this risk.
  * In February 2024, NIST announced the creation of [US AI Safety Institute](https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute) to support of efforts to create safe and trustworthy AI.

# Currently active NIST US AI Safety Institute Consortium
  * The CSU AI Safety and Security group discussion page related to USAISIC is [here](https://github.com/SteveKommrusch/CSU_AISafetySecurity/wiki/USAISIC)
  * There are 5 workgroups within the USAISIC:
    * Working Group #1: Risk Management for Generative AI [CSU AI Safety and Security discussion and notes](https://github.com/SteveKommrusch/CSU_AISafetySecurity/wiki/Working-Group-%231%3A-Risk-Management-for-Generative-AI)
    * Working Group #2: Synthetic Content
    * Working Group #3: Capability Evaluations
    * Working Group #4: Red-Teaming
    * Working Group #5: Safety & Security
